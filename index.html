<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Cheng Luo - Researcher</title>
  <link rel="stylesheet" href="style.css">
</head>

<body>
  <header>
    <h1>Cheng Luo</h1>
    <h2>Researcher</h2>
  </header>

  <nav>
    <ul>
      <li><a href="#about">About</a></li>
      <li><a href="#experience">Experience</a></li>
      <li><a href="#projects">Projects</a></li>
      <li><a href="#skills">Skills</a></li>
      <li><a href="#education">Education</a></li>
      <li><a href="#publications">Publications</a></li>
      <li><a href="#contact">Contact</a></li>
    </ul>
  </nav>

  <section id="about">
    <h2>About Me</h2>
    <p>I am a specialized researcher in systems and network research, focusing on system simulation and distributed training.
      My passion lies in utilizing simulation to enhance system performance in fields like satellite networks and distributed
      machine learning.</p>
    <p>Phone: (+1) 8586425898<br>
      Email: wdlctc@gmail.com<br>
      Location: San Diego, CA</p>
  </section>

  <section id="experience">
    <h2>Experience</h2>
    <ul>
      <li>
        <h3>System Researcher</h3>
        <h4>Microsoft, Shanghai</h4>
        <p>October 2021 - Present</p>
        <ul>
          <li>Led the development of novel algorithms for satellite selection and video bitrate optimization, utilizing model
            predictive control, dynamic programming, and reinforcement learning.</li>
          <li>Proposed and implemented a new scheduling algorithm for multi-talent distributed training, including co-design
            with computation and communication for overlapping behavior.</li>
          <li>Collaborated with Horovod to improve training performance.</li>
          <li>Created a simulation project for distributed training solutions on large-scale clusters, leveraging high-bandwidth
            InfiniBand and high-performance NVIDIA A100 GPU.</li>
          <li>Developed a benchmark tool for non-intrusive, fine-grained monitoring of AI infrastructure.</li>
        </ul>
      </li>
      <li>
        <h3>Microsoft Research Intern</h3>
        <h4>Shanghai & Beijing</h4>
        <p>June 2019 - September 2021</p>
        <ul>
          <li>Proposed and simulated a carbon-focused workload scheduler, achieving a 50% reduction in carbon emissions for
            ITP clusters.</li>
          <li>Developed an energy predictor for AI inference workloads on GPU, CPU, and VPU platforms using PyTorch and ONNX.</li>
          <li>Designed and implemented a new measurement tool for cloud GPU, focusing on latency, energy, and power, with
            fine-grained access to operation and kernel details.</li>
          <li>Implemented a high-throughput quantization algorithm for gradients communication, achieving 2x speedup using
            IC3 and ITP.</li>
        </ul>
      </li>
    </ul>
  </section>

  <section id="projects">
    <h2>Projects</h2>
    <ul>
      <li>
        <h3>SuperScalar</h3>
        <p>Innovated a new scheduling algorithm for multi-talent distributed training, optimizing system efficiency and
          performance. Successfully co-designed computation and communication overlapping behavior to reduce system latency.</p>
      </li>
      <li>
        <h3>Superbench</h3>
        <p>Spearheaded the development of a simulation project for distributed training solutions on large-scale clusters,
          utilizing high-bandwidth InfiniBand and high-performance NVIDIA A100 GPU. Crafted a user-friendly benchmark tool
          for non-intrusive, fine-grained monitoring of AI infrastructure, enhancing system transparency and maintainability.</p>
      </li>
    </ul>
  </section>

  <section id="skills">
    <h2>Skills</h2>
    <ul>
      <li>System Design: Video server, Satellite Communication, Simulation, Benchmark, Scheduler</li>
      <li>Software: AWS, Azure, NCCL, Nsight</li>
      <li>Hardware: NVIDIA, AMD, Xilinx, Altera, Intel, VPU, Mobile</li>
      <li>Programming: Python, C++, Verilog HDL</li>
    </ul>
  </section>

  <section id="education">
    <h2>Education</h2>
    <ul>
      <li>P.H.D., Master study at Fudan University (2016-2021)</li>
      <li>Participated in exchange programs at Imperial College London and University of Sydney</li>
    </ul>
  </section>

  <section id="publications">
    <h2>Publications</h2>
    <ul>
      <li>Luo C, He Z, Kyoungjun P, et al. Video-Aware Mobility Management for LEO Satellite Networks, submit to Mobicomm
        2023</li>
      <li>Jiamin L, Luo C, Ziyue Y, et al. Merak: An Analytical Performance Simulator for Large-scale Distributed Training,
        submit to MLSYS 2024</li>
      <li>Yuting J, Yifan X, Lei Q, Luo C, et al. Moneo: Non-intrusive Fine-grained Monitor for AI Infrastructure, accepted
        by ATC 2022</li>
      <li>Luo C, Sit M K, Fan H, et al. Towards Efficient Deep Neural Network Training by FPGA-Based Batch-Level Parallelism,
        FCCM, 2019</li>
    </ul>
  </section>

  <section id="contact">
    <h2>Contact Me</h2>
    <p>If you have any inquiries or would like to collaborate, feel free to reach out to me:</p>
    <ul>
      <li>Email: wdlctc@gmail.com</li>
      <li>Phone: (+1) 8586425898</li>
    </ul>
  </section>

  <script src="script.js"></script>
</body>

</html>
